\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{listings}
\usepackage{lmodern}

\title{Résumés de présentations}
\date{}

\begin{document}

\maketitle

\section*{Parallélisation automatique de boucles sur processeurs vectoriels}
Avec la fin imminente de la loi de Moore, il apparaît évident que les architectures courantes de processeurs sont appelées à changer. En fait, certains changements se sont déjà produit sans que la communauté en général ne s'en soit aperçu. Un exemple de ces changements est l'apparation de processeurs vectoriels promettant l'exécution simultanée de plusieurs intructions pour des gains de performances majeurs. Cette présentation abordera et fournira un début de réponse à la question: Comment puis-je accéder à ces gains de performance en faisant le moins d'effort possible? Pour ce faire, on s'attardera à l'architecture d'un compilateur moderne capable d'exploiter ce qui est en fait du parallèlisme au niveau des instructions.

\renewcommand\refname{Références Autovectorization}
\begin{thebibliography}{9}
\bibitem{1}
          Samuel P. Midkiff,
          \emph{Automatic Parallelization - An Overview of Fundamental Compiler Techniques},
          Morgan \& Claypool Publishers, 2012
          
\bibitem{2}
          Randy Allen \& Ken Kennedy,
          \emph{Optimizing Compilers for Modern Architectures: A Dependence-based Approach},
          Morgan Kaufmann, 2001
          
\bibitem{3}
          Nadav Rotem \& Arnold Schwaighofer,
          \emph{Vectorization in LLVM},
          LLVM Developpers Meeting, 2013
          
\bibitem{4}
          Jim Radigan,
          \emph{Inside Auto-Vectorization, 1 of n},
          Channel 9, 2012
          
\bibitem{5}
          Ayal Zaks \& Dorit Nuzman,
          \emph{Autovectorization in GCC-two years later},
          Channel 9, 2012
          
\bibitem{6}
          Ralf Karrenberg \& Sebastian Hack,
          \emph{Whole Function Vectorization},
          Proceedings of the Ninth International Symposium on Code Generation and Optimization, 2011
          
\bibitem{7}
          Saeed Maleki et al.,
          \emph{An Evaluation of Vectorizing Compilers},
          Proceedings of the 2011 International Conference on Parallel Architectures and Compilation Techniques, 2011
\end{thebibliography}

\newpage

\section*{Espace d'addressage global partitionné}
Selon les estimations présentes de compagnies comme Cray et Intel, d'ici 2020, les superordinateurs devraient offrir des puissances de calcul de l'ordre de l'exaflop ($10^{18}$ opérations en vigurle flottante à la seconde!) en utilisant environ 1 milliard (!) de \textit{threads} pour y arriver. Malheureusement, les approches traditionnelles comme MPI ne satisfont plus la demande à ce niveau. Face à un tel défi, il nous faut de nouveaux outils. Dans cette présentation, je vous invite à découvrir un nouveau modèle de programmation conçu spécifiquement pour l'\textit{exascale computing}: l'espace d'addressage global partitionné. 

\renewcommand\refname{Références PGAS}
\begin{thebibliography}{9}
\bibitem{1}
          Hartmut Kaiser \& Vinay Amatya,
          \emph{HPX: A C++ Standards Compliant Runtime System For Asynchronous Parallel And Distributed Computing}.
          C++Now, 2013.
          
\bibitem{2}
          Vijay Saraswat et al.,
          \emph{The Asynchronous Partitioned Global Address Space Model}.
          The First Workshop on Advances in Message Passing, 2011.
          
\bibitem{3}
          Georgel Calin et al.,
          \emph{A Theory of Partitioned Global Address Spaces}.
          http://arxiv.org/abs/1307.6590, 2013.
          
\bibitem{4}
          Bradford L. Chamberlain,
          \emph{A Brief Overview of Chapel}.
          2013.
          
\bibitem{5}
          hartmut Kaiser et al.,
          \emph{ParalleX: An Advanced Parallel Execution Model for Scaling-Impaired Applications}.
          International Conference on Parallel Processing Workshops, 2009.
\end{thebibliography}

\newpage

\section*{Techniques de programmation sans verrous}
Les verrous (mutex, sémaphores, etc...) sont les moyens les plus souvent utilisés pour raisonner sur un programme parallèle. Ils ne sont par contre pas toujours les moyens les plus efficaces pour implémenter des algorithmes et des structures de données parallèles. Dans cette présentation, je ferais un bref survol de techniques permettant de se libérer des verrous dans un contexte multiprogrammé ainsi que des dangers qui guettent ceux qui voudrait se risquer à les utiliser.

\renewcommand\refname{Références LockFree}
\begin{thebibliography}{9}
\bibitem{1}
          Herb Sutter,
          \emph{atomic<> Weapons}.
          C++ and Beyond, 2012.
          
\bibitem{2}
          Jeff Preshing,
          \emph{An Introduction to Lock-Free Programming}.
          Preshing on Programming, 2012.
          
\bibitem{3}
          Tony van Eerd,
          \emph{The Basics of Lock-Free Programming}.
          Boostcon, 2013.
          
\bibitem{4}
          Bruce Dawson
          \emph{Lockless Programming Considerations for Xbox 360 and Microsoft Windows}.
          Microsoft, 2013.
\end{thebibliography}

\newpage

\section*{Mémoire transactionnelle logicielle}
Dans le monde de la programmation parallèle, les verrous sont souvent un mal nécessaire. En effet, comment peut-on s'assurer de l'atomicité de certaines opérations sans eux? Jusqu'à tout récemment, aucune réponse satisfaisante n'avait été formulée. Ceci risque par contre de changer dans les prochaines années avec tout l'effort mis dans la mémoire transactionnelle logicielle. Cette présentation expliquera le pourquoi et le comment de cette technique de programmation parallèle. De plus, on y discutera aussi de l'aspect plus pratique de la chose en abordant des thèmes comme l'intégration de la mémoire transactionnelle dans des langages de programmation et les toutes dernières générations de processeurs.

\renewcommand\refname{Références STM}
\begin{thebibliography}{9}
\bibitem{1}
          Simon Peyton-Jones \& Tim Harris,
          \emph{Programming in the Age of Concurrency: Software Transactional Memory}.
          Channel 9, 2006.
          
\bibitem{2}
          Dave Boutcher,
          \emph{Software Transactional Memory in GCC 4.7}.
          Linux.conf.au, 2013.
          
\bibitem{3}
          Michael Neuling,
          \emph{What's the deal with Hardware Transactional Memory!?!}.
          Linux.conf.au, 2014.
          
\bibitem{4}
          Victor Luchangco et al.,
          \emph{Standard Wording for Transactional Memory Support in C++}.
          C++ Standards Committee Papers, 2014.
          
\bibitem{5}
          Simon Peyton Jones,
          \emph{Beautiful Concurrency}.
          Beautiful Code, O,Reilly, 2007.
         
\end{thebibliography}

\newpage

\section*{Détection dynamique de conditions de course}
Il va sans dire, corriger un programme parallèle est une des tâches les plus ardues auxquelles un programmeur peut être confronté. Dans l'espoir d'aider les programmeurs à régler des problèmes de multiprogrammation, plusieurs outils de détection de conditions de course ont été développés. Cette présentation se voudra une introduction à la théorie et aux algorithmes traînant derrière de tels outils.
\renewcommand\refname{Références TSan}
\begin{thebibliography}{9}
\bibitem{1}
          Stefan Savage et al.,
          \emph{Eraser: A Dynamic Data Race Detector for Multithreaded Programs}.
          ACM Trans. Comput. Syst., Nov. 1997
          
\bibitem{2}
          John Erickson et al.,
          \emph{Effective Data-race Detection for the Kernel}.
          Proceedings of the 9th USENIX Conference on Operating Systems Design and Implementation, 2010
          
\bibitem{3}
          Konstantin Serebryany \& Timur Iskhodzhanov,
          \emph{ThreadSanitizer: Data Race Detection in Practice}.
          Proceedings of the Workshop on Binary Instrumentation and Applications, 2009
          
\bibitem{4}
          Utpal Banerjee et al.,
          \emph{A Theory of Data Race Detection}.
          Proceedings of the 2006 Workshop on Parallel and Distributed Systems: Testing and Debugging, 2006
         
\end{thebibliography}

\newpage

\section*{Comportement et exploitation de la cache en multiprogrammation}
Un bon algorithme devrait être conscient du fait qu'il sera exécuté sur une machine possédant une hiérarchie mémoire comportant souvent plusieurs paliers. Il ne devrait cependant pas être trop attaché à la hiérarchie mémoire d'un processeur donné pour ne pas perdre de sa portabilité. Cela est d'autant plus vrai lorsque l'algorithme est développé pour être exécuter sur une machine multi-coeurs. Dans cette présentation, j'introduirai brièvement le fonctionnement des caches modernes pour ensuite discuter d'algorithmes et de structures de données exploitant ces dernières.
\renewcommand\refname{Références Cache}
\begin{thebibliography}{9}
\bibitem{1}
          Erik Demaine,
          \emph{Cache-Oblivious Algorithms and Data Structures}.
          Notes for MIT Computer Science 6.897: Advanced Data Structures, 2002.
          
\bibitem{2}
          Harald Prokop,
          \emph{Cache-Oblivious Algorithms}.
          Master's thesis, 1999.
          
\bibitem{3}
          Fabian Giesen
          \emph{Cache Coherency Primer}.
          http://fgiesen.wordpress.com/, 2014.
         
\end{thebibliography}

\newpage

\section*{Compilation polyhédrale}
Dans notre réalité de plus en plus axée sur la programmation parallèle, la parallélisation automatique est souvent considéré comme étant le but ultime à atteindre. Malheureusement, les avancées dans ce domaine de la compilation sont relativement faibles. Force est de constater que les anciennes méthodes utilisées pour découvrir et exploiter le parallélisme des applications sont insuffisantes. Dans cette présentation, j'offrirai un tour d'horizon du modèle de compilation polyhédral, un modèle récemment mis de l'avant avec Graphite (GCC) et Polly (LLVM) qui pourrait faire déboucher ce champ de recherche.
\renewcommand\refname{Références Poly}
\begin{thebibliography}{9}
\bibitem{1}
          Tobias Grosser,
          \emph{Enabling Polyhedral Optimizations in LLVM}.
          Master's thesis, 2011.

\bibitem{1}
          Ragesh A.,
          \emph{A Framework for Automatic OpenMP Code Generation}.
          Master's thesis, 2011.
          
\bibitem{1}
          Tomofumi Yuki,
          \emph{Beyond Shared Memory Loop Parallelism in the Polyhedral Model}.
          PhD's thesis, 2013.
          
\bibitem{1}
          Uday Bondhugula,
          \emph{Effective Automatic Parallelization and Locality Optimization using the Polyhedral Model}.
          PhD's thesis, 2010.                
\end{thebibliography}

\end{document}